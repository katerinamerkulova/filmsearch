{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## data analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vk_data = open(r'..\\..\\1. crawling & parsing\\vk_test_queries\\test_data.txt', encoding='utf-8').read().split('\\n')\n",
    "wiki_data = open(r'..\\..\\1. crawling & parsing\\wiki_film_descriptions\\film_plots.txt', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "vk_len = [len(x.split(' ')) for x in vk_data]\n",
    "wiki_len = [len(x.split(' ')) for x in wiki_data]\n",
    "vk_mean = sum(vk_len) / len(vk_len)\n",
    "wiki_mean = sum(wiki_len) / len(wiki_len)\n",
    "vk_variance = sum([(x - vk_mean) ** 2 for x in vk_len]) / len(vk_len)\n",
    "wiki_variance = sum([(x - wiki_mean) ** 2 for x in wiki_len]) / len(wiki_len)\n",
    "print(vk_mean, wiki_mean)\n",
    "print(vk_variance, wiki_variance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "not_main = ['nsubj', 'ROOT', 'nsubj:pass', 'punkt', 'subj', 'csubj', 'csubj:pass', 'xcomp', 'ccomp']\n",
    "def get_deps(data):\n",
    "    deps = []\n",
    "    for doc in nlp.pipe(tqdm(data)):\n",
    "        for sent in doc.sents:\n",
    "            sent_dep = []\n",
    "            for token in sent:\n",
    "                if token.dep_ not in not_main:\n",
    "                    sent_dep.append(token.dep_)\n",
    "            deps.append(len(sent_dep))\n",
    "    return deps\n",
    "\n",
    "def get_deps_distr(data):\n",
    "    deps = []\n",
    "    for doc in nlp.pipe(tqdm(data)):\n",
    "        for sent in doc.sents:\n",
    "            for token in sent:\n",
    "                deps.append(token.dep_)\n",
    "    return deps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vk_deps = get_deps(vk_data)\n",
    "wiki_deps = get_deps(wiki_data[:1000])\n",
    "# sum(vk_deps) / len(vk_deps), sum(wiki_deps) / len(wiki_deps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vk_distr = get_deps_distr(vk_data)\n",
    "wiki_distr = get_deps_distr(wiki_data[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(vk_distr).value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(wiki_distr).value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## predicts analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "minilm_json_100 = json.load(open('MiniLM search result 100.json', encoding='utf-8'))\n",
    "tfidf_json_100 = json.load(open('TD-IDF search result 100.json', encoding='utf-8'))\n",
    "minilm_json_1000 = json.load(open('MiniLM search result 1000.json', encoding='utf-8'))\n",
    "tfidf_json_1000 = json.load(open('TD-IDF search result 1000.json', encoding='utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_scores(minilm_json, tfidf_json):\n",
    "    inter = []\n",
    "    scores = {\n",
    "        'Общие правильные': 0,\n",
    "        'Общие неправильные': 0,\n",
    "        'Только TF-IDF правильные': 0,\n",
    "        'Только MiniLM правильные': 0,\n",
    "        'Всего': 0\n",
    "    }\n",
    "    minilm, only_minilm = [], []\n",
    "    tfidf, only_tfidf = [], []\n",
    "    not_found = []\n",
    "\n",
    "    for (query_i, result_i), (query_j, result_j) in zip(minilm_json.items(), tfidf_json.items()):\n",
    "        inter.append(len(set(result_i['predicted']).intersection(set(result_j['predicted']))) / 10)\n",
    "\n",
    "        for true in result_i['true']:\n",
    "            if true in result_i['predicted'] and true in result_j['predicted']:\n",
    "                scores['Общие правильные'] += 1\n",
    "                minilm.append(\n",
    "                    ('MiniLM',\n",
    "                     len(result_i['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "                tfidf.append(\n",
    "                    ('TF-IDF',\n",
    "                     len(result_j['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            elif true in result_i['predicted']:\n",
    "                scores['Только MiniLM правильные'] += 1\n",
    "                minilm.append(\n",
    "                    ('MiniLM',\n",
    "                     len(result_i['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "                only_minilm.append(\n",
    "                    ('MiniLM',\n",
    "                     len(result_i['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            elif true in result_j['predicted']:\n",
    "                scores['Только TF-IDF правильные'] += 1\n",
    "                tfidf.append(\n",
    "                    ('TF-IDF',\n",
    "                     len(result_j['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "                only_tfidf.append(\n",
    "                    ('TF-IDF',\n",
    "                     len(result_j['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            else:\n",
    "                scores['Общие неправильные'] += 1\n",
    "                not_found.append(\n",
    "                    ('NA',\n",
    "                     len(result_j['true'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            scores['Всего'] += 1\n",
    "\n",
    "    # print(sum(inter) / len(inter))\n",
    "    # for name, value in scores.items():\n",
    "        # print(name, value, round(value / scores['Всего'], 2))\n",
    "    return scores, minilm, tfidf, not_found\n",
    "\n",
    "scores, minilm, tfidf, not_found = get_scores(minilm_json_100, tfidf_json_100)\n",
    "# get_scores(minilm_json_1000, tfidf_json_1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# средняя длина описаний фильмов, правильно найденных только одним методом\n",
    "# нейронка плохо подходит для длинных текстов, не хвататет выразительной способности\n",
    "print(sum([x[1] for x in only_minilm]) / len(only_minilm), sum([x[1] for x in only_tfidf]) / len(only_tfidf))\n",
    "\n",
    "# средняя длина запросов фильмов, правильно найденных только одним методом\n",
    "print(sum([x[2] for x in only_minilm]) / len(only_minilm), sum([x[2] for x in only_tfidf]) / len(only_tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sum([x[1] for x in minilm]) / len(minilm), sum([x[1] for x in tfidf]) / len(tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# средняя длина описаний фильмов, правильно найденных\n",
    "sns.histplot([x[1] for x in minilm], label='MiniLM', bins=20, kde=True, color='r', stat='density')\n",
    "sns.histplot([x[1] for x in tfidf], label='TF-IDF', bins=20, kde=True, color='g', stat='density')\n",
    "sns.histplot([x[1] for x in not_found], label='not found', bins=20, kde=True, color='b', stat='density')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# средняя длина описаний фильмов, правильно найденных только одним методом\n",
    "sns.histplot([x[1] for x in only_minilm], label='MiniLM', kde=True, color='r', stat='density')\n",
    "sns.histplot([x[1] for x in only_tfidf], label='TF-IDF', kde=True, color='g', stat='density')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# корреляция с кол-вом вариантов заголовков для запросов в правильных ответах\n",
    "res = []\n",
    "for (query_i, result_i), (query_j, result_j) in zip(minilm_json_100.items(), tfidf_json_100.items()):\n",
    "    frac_minilm = [1 if title in result_i['predicted'] else 0 for title in result_i['true']]\n",
    "    frac_tfidf = [1 if title in result_j['predicted'] else 0 for title in result_j['true']]\n",
    "    res.append((len(result_i['true']),\n",
    "                sum(frac_minilm) / len(frac_minilm),\n",
    "                sum(frac_tfidf) / len(frac_tfidf)\n",
    "                ))\n",
    "\n",
    "res_df = pd.DataFrame(res, columns=['n_true', 'frac_minilm', 'frac_tfidf'])\n",
    "res_df.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}