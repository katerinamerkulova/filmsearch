{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## data analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.891 208.14355245075583\n",
      "1462.7231189999995 76891.80566388102\n"
     ]
    }
   ],
   "source": [
    "vk_data = open(r'..\\..\\1. crawling & parsing\\vk_test_queries\\test_data.txt', encoding='utf-8').read().split('\\n')\n",
    "wiki_data = open(r'..\\..\\1. crawling & parsing\\wiki_film_descriptions\\film_plots.txt', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "vk_len = [len(x.split(' ')) for x in vk_data]\n",
    "wiki_len = [len(x.split(' ')) for x in wiki_data]\n",
    "vk_mean = sum(vk_len) / len(vk_len)\n",
    "wiki_mean = sum(wiki_len) / len(wiki_len)\n",
    "vk_variance = sum([(x - vk_mean) ** 2 for x in vk_len]) / len(vk_len)\n",
    "wiki_variance = sum([(x - wiki_mean) ** 2 for x in wiki_len]) / len(wiki_len)\n",
    "print(vk_mean, wiki_mean)\n",
    "print(vk_variance, wiki_variance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "not_main = ['nsubj', 'ROOT', 'nsubj:pass', 'punkt', 'subj', 'csubj', 'csubj:pass', 'xcomp', 'ccomp']\n",
    "def get_deps(data):\n",
    "    deps = []\n",
    "    for doc in nlp.pipe(tqdm(data)):\n",
    "        for sent in doc.sents:\n",
    "            sent_dep = []\n",
    "            for token in sent:\n",
    "                if token.dep_ not in not_main:\n",
    "                    sent_dep.append(token.dep_)\n",
    "            deps.append(len(sent_dep))\n",
    "    return deps\n",
    "\n",
    "def get_deps_distr(data):\n",
    "    deps = []\n",
    "    i = 0\n",
    "    for doc in nlp.pipe(tqdm(data)):\n",
    "        for sent in doc.sents:\n",
    "            for token in sent:\n",
    "                deps.append(token.dep_)\n",
    "                # deps.append(token.tag_)\n",
    "                if token.text == \"не\":\n",
    "                    i += 1\n",
    "    print(i, i / len(deps))\n",
    "    return deps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vk_deps = get_deps(vk_data)\n",
    "wiki_deps = get_deps(wiki_data[:1000])\n",
    "# sum(vk_deps) / len(vk_deps), sum(wiki_deps) / len(wiki_deps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "190bd91d3a264d94999265c537cc1162"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594 0.009709372650299128\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e151bc1ef8c4f1d9b8559892b2cd34e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690 0.006603909983626992\n"
     ]
    }
   ],
   "source": [
    "vk_distr = get_deps_distr(vk_data)\n",
    "wiki_distr = get_deps_distr(wiki_data[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "punct            0.139478\ncase             0.105381\nnsubj            0.101049\nobl              0.080813\nconj             0.076760\nadvmod           0.072052\nobj              0.055576\nnmod             0.054546\nROOT             0.054497\ncc               0.051505\namod             0.038543\ndet              0.037383\nxcomp            0.018471\nmark             0.015479\nparataxis        0.013927\nappos            0.011213\nnummod           0.010788\niobj             0.010543\nfixed            0.008304\nacl:relcl        0.006931\ncop              0.006555\nadvcl            0.006375\nccomp            0.006277\nacl              0.004610\nnummod:gov       0.003498\nnsubj:pass       0.002632\nflat:name        0.001487\ndiscourse        0.001406\ncsubj            0.001357\naux              0.001062\naux:pass         0.000932\norphan           0.000114\nobl:agent        0.000098\nflat             0.000098\nexpl             0.000065\nflat:foreign     0.000065\nnummod:entity    0.000049\ncsubj:pass       0.000049\ncompound         0.000033\ndtype: float64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(vk_distr).value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "punct            0.165176\ncase             0.104916\nobl              0.085386\nnsubj            0.080716\nnmod             0.071111\namod             0.060084\nobj              0.053523\nROOT             0.051299\nconj             0.051284\nadvmod           0.046024\ncc               0.039737\nappos            0.023532\nxcomp            0.022293\ndet              0.021984\nmark             0.016916\nadvcl            0.013989\niobj             0.012235\nacl              0.010934\nacl:relcl        0.010898\nparataxis        0.010547\nflat:name        0.010269\nfixed            0.008581\nccomp            0.007085\nnummod           0.004314\nnsubj:pass       0.003951\nflat:foreign     0.002700\nnummod:gov       0.002657\ncsubj            0.001817\ncop              0.001536\naux:pass         0.001375\nobl:agent        0.001121\naux              0.000617\ndiscourse        0.000598\nflat             0.000231\norphan           0.000195\nexpl             0.000148\nnummod:entity    0.000090\ncsubj:pass       0.000086\ncompound         0.000035\nlist             0.000008\ndtype: float64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(wiki_distr).value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## predicts analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "minilm_json_100 = json.load(open('MiniLM search result 100.json', encoding='utf-8'))\n",
    "tfidf_json_100 = json.load(open('TD-IDF search result 100.json', encoding='utf-8'))\n",
    "minilm_json_1000 = json.load(open('MiniLM search result 1000.json', encoding='utf-8'))\n",
    "tfidf_json_1000 = json.load(open('TD-IDF search result 1000.json', encoding='utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_scores(minilm_json, tfidf_json):\n",
    "    inter = []\n",
    "    scores = {\n",
    "        'Общие правильные': 0,\n",
    "        'Общие неправильные': 0,\n",
    "        'Только TF-IDF правильные': 0,\n",
    "        'Только MiniLM правильные': 0,\n",
    "        'Всего': 0\n",
    "    }\n",
    "    minilm, only_minilm = [], []\n",
    "    tfidf, only_tfidf = [], []\n",
    "    not_found = []\n",
    "\n",
    "    for (query_i, result_i), (query_j, result_j) in zip(minilm_json.items(), tfidf_json.items()):\n",
    "        inter.append(len(set(result_i['predicted']).intersection(set(result_j['predicted']))) / 10)\n",
    "\n",
    "        for true in result_i['true']:\n",
    "            if true in result_i['predicted'] and true in result_j['predicted']:\n",
    "                scores['Общие правильные'] += 1\n",
    "                minilm.append(\n",
    "                    ('MiniLM',\n",
    "                     len(result_i['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "                tfidf.append(\n",
    "                    ('TF-IDF',\n",
    "                     len(result_j['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            elif true in result_i['predicted']:\n",
    "                scores['Только MiniLM правильные'] += 1\n",
    "                minilm.append(\n",
    "                    ('MiniLM',\n",
    "                     len(result_i['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "                only_minilm.append(\n",
    "                    ('MiniLM',\n",
    "                     len(result_i['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            elif true in result_j['predicted']:\n",
    "                scores['Только TF-IDF правильные'] += 1\n",
    "                tfidf.append(\n",
    "                    ('TF-IDF',\n",
    "                     len(result_j['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "                only_tfidf.append(\n",
    "                    ('TF-IDF',\n",
    "                     len(result_j['predicted'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            else:\n",
    "                scores['Общие неправильные'] += 1\n",
    "                not_found.append(\n",
    "                    ('NA',\n",
    "                     len(result_j['true'][true].split(' ')),\n",
    "                     len(query_i.split(' ')),\n",
    "                     query_i, true)\n",
    "                )\n",
    "            scores['Всего'] += 1\n",
    "\n",
    "    # print(sum(inter) / len(inter))\n",
    "    # for name, value in scores.items():\n",
    "        # print(name, value, round(value / scores['Всего'], 2))\n",
    "    return scores, minilm, tfidf, not_found\n",
    "\n",
    "scores, minilm, tfidf, not_found = get_scores(minilm_json_100, tfidf_json_100)\n",
    "# get_scores(minilm_json_1000, tfidf_json_1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# средняя длина описаний фильмов, правильно найденных только одним методом\n",
    "# нейронка плохо подходит для длинных текстов, не хвататет выразительной способности\n",
    "print(sum([x[1] for x in only_minilm]) / len(only_minilm), sum([x[1] for x in only_tfidf]) / len(only_tfidf))\n",
    "\n",
    "# средняя длина запросов фильмов, правильно найденных только одним методом\n",
    "print(sum([x[2] for x in only_minilm]) / len(only_minilm), sum([x[2] for x in only_tfidf]) / len(only_tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sum([x[1] for x in minilm]) / len(minilm), sum([x[1] for x in tfidf]) / len(tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# средняя длина описаний фильмов, правильно найденных\n",
    "sns.histplot([x[1] for x in minilm], label='MiniLM', bins=20, kde=True, color='r', stat='density')\n",
    "sns.histplot([x[1] for x in tfidf], label='TF-IDF', bins=20, kde=True, color='g', stat='density')\n",
    "sns.histplot([x[1] for x in not_found], label='not found', bins=20, kde=True, color='b', stat='density')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# средняя длина описаний фильмов, правильно найденных только одним методом\n",
    "sns.histplot([x[1] for x in only_minilm], label='MiniLM', kde=True, color='r', stat='density')\n",
    "sns.histplot([x[1] for x in only_tfidf], label='TF-IDF', kde=True, color='g', stat='density')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# корреляция с кол-вом вариантов заголовков для запросов в правильных ответах\n",
    "res = []\n",
    "for (query_i, result_i), (query_j, result_j) in zip(minilm_json_100.items(), tfidf_json_100.items()):\n",
    "    frac_minilm = [1 if title in result_i['predicted'] else 0 for title in result_i['true']]\n",
    "    frac_tfidf = [1 if title in result_j['predicted'] else 0 for title in result_j['true']]\n",
    "    res.append((len(result_i['true']),\n",
    "                sum(frac_minilm) / len(frac_minilm),\n",
    "                sum(frac_tfidf) / len(frac_tfidf)\n",
    "                ))\n",
    "\n",
    "res_df = pd.DataFrame(res, columns=['n_true', 'frac_minilm', 'frac_tfidf'])\n",
    "res_df.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}