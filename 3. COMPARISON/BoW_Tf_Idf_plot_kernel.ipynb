{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoW Tf-Idf plot kernel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LduV2CFKAv2d"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "from scipy import spatial\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from time import process_time\r\n",
        "\r\n",
        "stops = open('/content/drive/MyDrive/Colab Notebooks/russian.txt').read().split()\r\n",
        "\r\n",
        "def open_data(size):\r\n",
        "    y_train, x_train, y_test, x_test = open(f'/content/drive/MyDrive/Colab Notebooks/data_spacy/data_{size}.txt', encoding='utf-8').read().split('\\n&&&\\n')\r\n",
        "    y_train, x_train, y_test, x_test = y_train.split('\\n'), x_train.split('\\n'), y_test.split('\\n'), x_test.split('\\n')\r\n",
        "    return y_train, x_train, y_test, x_test"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB0o1U94CLtw"
      },
      "source": [
        "def ap(relev, k):    # average presicion\r\n",
        "    ap = []\r\n",
        "    for i in range(1, k):\r\n",
        "        if relev[i-1] is 1:    # if doc is relevant\r\n",
        "            ap.append(sum(relev[:i])/i)    # summary of precisions\r\n",
        "    try: \r\n",
        "        ap = sum(ap)/sum(relev)\r\n",
        "    except ZeroDivisionError:\r\n",
        "        ap = 0.0\r\n",
        "    return ap\r\n",
        "\r\n",
        "def evaluation(query, relev, index=0, k=10):    # mean average precision (10)\r\n",
        "    prec = round(sum(relev)/k, 4)    # rank is not take into account\r\n",
        "    k += 1\r\n",
        "    avp = ap(relev, k)    # rank is take into account\r\n",
        "    evaluat = pd.DataFrame({'precision': prec,\r\n",
        "                            'average_precision': avp},\r\n",
        "                            index=[index])\r\n",
        "    return evaluat\r\n",
        "\r\n",
        "def retrieval(fit, predict, y_train, x_train, y_test, x_test):\r\n",
        "    df = pd.DataFrame(columns=['query', 'precision', 'average_precision'])\r\n",
        "    train_start = process_time()\r\n",
        "    x = fit(x_train)\r\n",
        "    train_stop = process_time()\r\n",
        "    train_time = train_stop - train_start\r\n",
        "\r\n",
        "    test_start = process_time()\r\n",
        "    for index, query in enumerate(x_test):\r\n",
        "        predictions = predict(x, query, y_train)\r\n",
        "        relev = [0] * 10\r\n",
        "        for i, pred in enumerate(predictions):\r\n",
        "            if pred[1] == y_test[index]:\r\n",
        "                relev[i] = 1\r\n",
        "        if relev != [0] * 10:\r\n",
        "            df = df.append(evaluation(query, relev, index))\r\n",
        "        else:\r\n",
        "            df2 = pd.DataFrame({'precision': 0.0,\r\n",
        "                                'average_precision': 0.0},\r\n",
        "                                index=[index])\r\n",
        "            df = df.append(df2)\r\n",
        "    test_stop = process_time()\r\n",
        "    test_time = test_stop - test_start\r\n",
        "    return df, train_time, test_time\r\n",
        "# map = sum(ap)/Q    # Q - number of quaries\r\n",
        "# recall = sum(p)/Q\r\n",
        "MAP = pd.DataFrame(columns=[\r\n",
        "  'embedding',\r\n",
        "  'train size',\r\n",
        "  'test size', \r\n",
        "  'training time', \r\n",
        "  'inference time', \r\n",
        "  'recall', \r\n",
        "  'MAP'\r\n",
        "])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do8yePRVAnPO",
        "outputId": "5de55544-89ab-4e9d-b643-1eac0f742799"
      },
      "source": [
        "vectorizers = [CountVectorizer(stop_words=stops)] * 2  # 100, 500\r\n",
        "vectorizers += [CountVectorizer(max_df=0.7, min_df=0.1, max_features=15000, stop_words=stops)] * 6  # 837, 1000, 5000, 10000, 20000, 30000\r\n",
        "\r\n",
        "# fitting\r\n",
        "def CV_fit(x_train):    \r\n",
        "    X = vectorizer.fit_transform(x_train)\r\n",
        "    return X.toarray()\r\n",
        "\r\n",
        "# similarity\r\n",
        "def CV_predict(x, query, y_train):\r\n",
        "    pred = []\r\n",
        "    vec = vectorizer.transform([query]).toarray()\r\n",
        "    simil = []\r\n",
        "    for vector, film in zip(x, y_train):\r\n",
        "        simil.append([1 - spatial.distance.cosine(vector, vec), film])\r\n",
        "    simil.sort(reverse=True)\r\n",
        "    for sim in simil[:10]:\r\n",
        "        pred.append(sim)\r\n",
        "    return pred\r\n",
        "\r\n",
        "for i, size, vectorizer in zip((0, 1, 2, 3, 4, 5, 6, 7),\r\n",
        "                               (100, 500, 837, 1000, 5000, 10000, 20000, 30000),\r\n",
        "                               vectorizers):\r\n",
        "    y_train, x_train, y_test, x_test = open_data(size)\r\n",
        "    df, train_time, test_time = retrieval(CV_fit, CV_predict, y_train, x_train, y_test, x_test)\r\n",
        "    print(f'done {size}')\r\n",
        "    df2 = pd.DataFrame({'embedding': 'CountVectorizer',\r\n",
        "                        'train size': len(y_train),\r\n",
        "                        'test size': len(y_test),\r\n",
        "                        'training time': round(train_time, 2),\r\n",
        "                        'inference time': round(test_time / len(y_test), 2),\r\n",
        "                        'recall': round(len([1 for prec in df.precision if prec != 0])/len(y_test), 4),\r\n",
        "                        'MAP': round(sum(df.average_precision)/len(y_test), 4)},\r\n",
        "                        index=[i])\r\n",
        "    MAP = MAP.append(df2)\r\n",
        "    MAP.to_csv('/content/drive/MyDrive/Colab Notebooks/data_spacy/MAP_kernel_plot.csv', index=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done 100\n",
            "done 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done 837\n",
            "done 1000\n",
            "done 5000\n",
            "done 10000\n",
            "done 20000\n",
            "done 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCPHq-lGCV2T"
      },
      "source": [
        "vectorizers = [TfidfVectorizer(stop_words=stops)] * 2  # 100, 500\r\n",
        "vectorizers += [TfidfVectorizer(max_df=0.7, min_df=0.1, max_features=15000, stop_words=stops)] * 6  # 837, 1000, 5000, 10000, 20000, 30000\r\n",
        "\r\n",
        "# fitting\r\n",
        "def tfidf_fit(x_train):\r\n",
        "    X = vectorizer.fit_transform(x_train)\r\n",
        "    return X.toarray()\r\n",
        "\r\n",
        "# similarity\r\n",
        "def tfidf_predict(x, query, y_train):\r\n",
        "    pred = []\r\n",
        "    vec = vectorizer.transform([query]).toarray()\r\n",
        "    simil = []\r\n",
        "    for vector, film in zip(x, y_train):\r\n",
        "        simil.append([1 - spatial.distance.cosine(vector, vec), film])\r\n",
        "    simil.sort(reverse=True)\r\n",
        "    for sim in simil[:10]:\r\n",
        "        pred.append(sim)\r\n",
        "    return pred\r\n",
        "\r\n",
        "\r\n",
        "for i, size, vectorizer in zip((8, 9, 10, 11, 12, 13, 14, 15),\r\n",
        "                               (100, 500, 837, 1000, 5000, 10000, 20000, 30000),\r\n",
        "                               vectorizers):\r\n",
        "    y_train, x_train, y_test, x_test = open_data(size)\r\n",
        "    df, train_time, test_time  = retrieval(tfidf_fit, tfidf_predict, y_train, x_train, y_test, x_test)\r\n",
        "    print(f'done {size}')\r\n",
        "    df2 = pd.DataFrame({'embedding': 'TF-IDF',\r\n",
        "                        'train size': len(y_train),\r\n",
        "                        'test size': len(y_test),\r\n",
        "                        'training time': round(train_time, 2),\r\n",
        "                        'inference time': round(test_time / len(y_test), 2),\r\n",
        "                        'recall': round(len([1 for prec in df.precision if prec != 0])/len(y_test), 4),\r\n",
        "                        'MAP': round(sum(df.average_precision)/len(y_test), 4)},\r\n",
        "                        index=[i])\r\n",
        "    MAP = MAP.append(df2)\r\n",
        "    MAP.to_csv('/content/drive/MyDrive/Colab Notebooks/data_spacy/MAP_kernel_plot.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}